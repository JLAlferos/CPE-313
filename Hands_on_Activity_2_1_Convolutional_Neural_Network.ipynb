{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "historic-trainer",
      "metadata": {
        "id": "historic-trainer"
      },
      "source": [
        "# Activity 2.1 : Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "olive-manner",
      "metadata": {
        "id": "olive-manner"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to introduce how to build a convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "happy-transport",
      "metadata": {
        "id": "happy-transport"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train convolutional neural network\n",
        "* Evaluate the accuracy and loss of the model using convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "leading-providence",
      "metadata": {
        "id": "leading-providence"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "* CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "literary-trail",
      "metadata": {
        "id": "literary-trail"
      },
      "source": [
        "#### Procedures\n",
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "stretch-active",
      "metadata": {
        "id": "stretch-active"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "collaborative-seating",
      "metadata": {
        "id": "collaborative-seating"
      },
      "source": [
        "* Shuffle the data\n",
        "* Split the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "modular-springer",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "modular-springer",
        "outputId": "1a641fc8-f4db-49c2-c208-7c5eb4076fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "female-carolina",
      "metadata": {
        "id": "female-carolina"
      },
      "source": [
        "Check the image size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "alleged-stephen",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alleged-stephen",
        "outputId": "9d275a41-3466-4311-e91d-6509631dcd57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "x_train[444].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conscious-twenty",
      "metadata": {
        "id": "conscious-twenty"
      },
      "source": [
        "Visualize one of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "positive-creation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "positive-creation",
        "outputId": "9d988562-0c65-4adb-a01a-e590d5835c22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(y_train[444])\n",
        "plt.imshow(x_train[444]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "animated-rotation",
      "metadata": {
        "id": "animated-rotation"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "severe-filing",
      "metadata": {
        "id": "severe-filing"
      },
      "source": [
        "Instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "genetic-centre",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "genetic-centre",
        "outputId": "4291ceec-ab59-49db-fade-8709deda8eb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[444]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "detected-education",
      "metadata": {
        "id": "detected-education"
      },
      "source": [
        "Convert to float and scale the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "familiar-damages",
      "metadata": {
        "id": "familiar-damages"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bizarre-smith",
      "metadata": {
        "id": "bizarre-smith"
      },
      "source": [
        "Build a CNN using Keras Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "understanding-milan",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "understanding-milan",
        "outputId": "702f4d3e-e2a9-403b-c1ec-fa8c5638b0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 16, 16, 32)        2432      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 3, 3, 32)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 288)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               147968    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181,162\n",
            "Trainable params: 181,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baking-portable",
      "metadata": {
        "id": "baking-portable"
      },
      "source": [
        "* Use batch size of 32\n",
        "* Initiate RMSprop optimizer\n",
        "* Train the model using RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "removed-memorial",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "removed-memorial",
        "outputId": "e84021b7-3a58-47e8-8de7-80bc212af370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 19s 5ms/step - loss: 1.7205 - accuracy: 0.3746 - val_loss: 1.4496 - val_accuracy: 0.4813\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.4498 - accuracy: 0.4774 - val_loss: 1.3383 - val_accuracy: 0.5189\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3511 - accuracy: 0.5166 - val_loss: 1.2591 - val_accuracy: 0.5555\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2791 - accuracy: 0.5449 - val_loss: 1.3182 - val_accuracy: 0.5236\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2348 - accuracy: 0.5617 - val_loss: 1.1215 - val_accuracy: 0.6057\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2007 - accuracy: 0.5756 - val_loss: 1.1060 - val_accuracy: 0.6071\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1697 - accuracy: 0.5893 - val_loss: 1.1454 - val_accuracy: 0.5905\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1487 - accuracy: 0.5970 - val_loss: 1.1116 - val_accuracy: 0.6196\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1313 - accuracy: 0.6043 - val_loss: 1.0689 - val_accuracy: 0.6289\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1149 - accuracy: 0.6104 - val_loss: 1.1212 - val_accuracy: 0.6201\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1082 - accuracy: 0.6160 - val_loss: 1.0397 - val_accuracy: 0.6423\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0971 - accuracy: 0.6213 - val_loss: 1.0846 - val_accuracy: 0.6349\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0887 - accuracy: 0.6249 - val_loss: 1.0524 - val_accuracy: 0.6411\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0804 - accuracy: 0.6290 - val_loss: 1.0581 - val_accuracy: 0.6396\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0756 - accuracy: 0.6318 - val_loss: 1.0563 - val_accuracy: 0.6469\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x24396e10b20>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jewish-lambda",
      "metadata": {
        "id": "jewish-lambda"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "southeast-theater",
      "metadata": {
        "id": "southeast-theater"
      },
      "source": [
        "* Build a more complicated model with the following pattern:\n",
        "Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "\n",
        "* Use strides of 1 for all convolutional layers.\n",
        "\n",
        "* Write the number of parameters of your model  and compare it to the previous model\n",
        "\n",
        "* Train it for 5 epochs. Commpare the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
        "\n",
        "* Use different structures and run times, and see how accurate your model can be."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b55ca2e6",
      "metadata": {},
      "source": [
        "### Build a more complicated model with the following pattern: Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "### Use strides of 1 for all convolutional layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "60076636",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)        2432      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 32)        25632     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 10, 10, 32)        25632     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 10, 10, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 6, 6, 32)          25632     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3, 3, 32)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               147968    \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232,426\n",
            "Trainable params: 232,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_supple = Sequential()\n",
        "\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_supple.add(Conv2D(32, (5, 5), strides = (1,1), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_supple.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_supple.add(Conv2D(32, (5, 5), strides = (1,1)))\n",
        "model_supple.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_supple.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_supple.add(Dropout(0.25))\n",
        "\n",
        "model_supple.add(Conv2D(32, (5, 5), strides = (1,1)))\n",
        "model_supple.add(Activation('relu'))\n",
        "\n",
        "model_supple.add(Conv2D(32, (5, 5), strides = (1,1)))\n",
        "model_supple.add(Activation('relu'))\n",
        "\n",
        "model_supple.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_supple.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_supple.add(Flatten())\n",
        "model_supple.add(Dense(512))\n",
        "model_supple.add(Activation('relu'))\n",
        "model_supple.add(Dropout(0.5))\n",
        "model_supple.add(Dense(num_classes))\n",
        "model_supple.add(Activation('softmax'))\n",
        "\n",
        "model_supple.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d9e282",
      "metadata": {},
      "source": [
        "### Write the number of parameters of your model  and compare it to the previous model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f861ffa",
      "metadata": {},
      "source": [
        "> The total parameters of supple model is 232426, while the procedure model is 181162. We can see that the supple model has more parameters compared to the procedure model due to its increased number of convolution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "562e11b2",
      "metadata": {},
      "source": [
        "### Train it for 5 epochs. Commpare the training time, loss and accuracy numbers (on both the training and validation sets)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6f516fcc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7086 - accuracy: 0.3694 - val_loss: 1.5564 - val_accuracy: 0.4598\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3111 - accuracy: 0.5329 - val_loss: 1.2114 - val_accuracy: 0.5695\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1645 - accuracy: 0.5902 - val_loss: 1.0628 - val_accuracy: 0.6220\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0786 - accuracy: 0.6235 - val_loss: 1.0164 - val_accuracy: 0.6416\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0250 - accuracy: 0.6433 - val_loss: 0.9641 - val_accuracy: 0.6632\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x244bf676a90>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "model_supple.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_supple.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ceb2b9",
      "metadata": {},
      "source": [
        "\n",
        "> In training the models, supple model has a faster training time due to its smaller epoch compared to procedure model. Upon looking on their results, supple model has a lower loss and higher accuracy than the procedure model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "637e8c37",
      "metadata": {},
      "source": [
        "### Use different structures and run times, and see how accurate your model can be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9606e586",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_supple1 = Sequential()\n",
        "\n",
        "# Convolutional Layer\n",
        "model_supple1.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model_supple1.add(BatchNormalization())\n",
        "model_supple1.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model_supple1.add(BatchNormalization())\n",
        "\n",
        "# Pooling layer\n",
        "model_supple1.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "# Dropout layers\n",
        "model_supple1.add(Dropout(0.25))\n",
        "\n",
        "model_supple1.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model_supple1.add(BatchNormalization())\n",
        "model_supple1.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model_supple1.add(BatchNormalization())\n",
        "\n",
        "model_supple1.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model_supple1.add(Dropout(0.25))\n",
        "\n",
        "model_supple1.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model_supple1.add(BatchNormalization())\n",
        "model_supple1.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model_supple1.add(BatchNormalization())\n",
        "model_supple1.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model_supple1.add(Dropout(0.25))\n",
        "\n",
        "model_supple1.add(Flatten())\n",
        "\n",
        "# model.add(Dropout(0.2))\n",
        "model_supple1.add(Dense(128, activation='relu'))\n",
        "model_supple1.add(Dropout(0.25))\n",
        "model_supple1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "METRICS = [\n",
        "    'accuracy',\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "model_supple1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7c6a4d97",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 4, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114,858\n",
            "Trainable params: 114,474\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_supple1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8dabb92f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 17s 10ms/step - loss: 1.6923 - accuracy: 0.3913 - val_loss: 1.4174 - val_accuracy: 0.4941\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.2564 - accuracy: 0.5517 - val_loss: 1.1663 - val_accuracy: 0.5923\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.0913 - accuracy: 0.6130 - val_loss: 0.9618 - val_accuracy: 0.6606\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.9898 - accuracy: 0.6525 - val_loss: 0.9632 - val_accuracy: 0.6534\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.9178 - accuracy: 0.6785 - val_loss: 0.9267 - val_accuracy: 0.6850\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.8649 - accuracy: 0.6966 - val_loss: 0.8726 - val_accuracy: 0.6950\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.8203 - accuracy: 0.7154 - val_loss: 0.7342 - val_accuracy: 0.7487\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.8003 - accuracy: 0.7218 - val_loss: 0.7317 - val_accuracy: 0.7499\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.7647 - accuracy: 0.7342 - val_loss: 0.7120 - val_accuracy: 0.7581\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.7419 - accuracy: 0.7437 - val_loss: 0.6700 - val_accuracy: 0.7670\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.7155 - accuracy: 0.7524 - val_loss: 0.6784 - val_accuracy: 0.7708\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6953 - accuracy: 0.7574 - val_loss: 0.6446 - val_accuracy: 0.7778\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.6787 - accuracy: 0.7629 - val_loss: 0.6550 - val_accuracy: 0.7740\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6610 - accuracy: 0.7700 - val_loss: 0.7723 - val_accuracy: 0.7382\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6462 - accuracy: 0.7762 - val_loss: 0.6615 - val_accuracy: 0.7735\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6388 - accuracy: 0.7784 - val_loss: 0.7870 - val_accuracy: 0.7290\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6245 - accuracy: 0.7818 - val_loss: 0.6317 - val_accuracy: 0.7857\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6119 - accuracy: 0.7849 - val_loss: 0.6057 - val_accuracy: 0.7922\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.6023 - accuracy: 0.7905 - val_loss: 0.9616 - val_accuracy: 0.6990\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5911 - accuracy: 0.7937 - val_loss: 0.6403 - val_accuracy: 0.7851\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5829 - accuracy: 0.7966 - val_loss: 0.5989 - val_accuracy: 0.7987\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.5710 - accuracy: 0.8017 - val_loss: 0.6172 - val_accuracy: 0.7919\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.5658 - accuracy: 0.8045 - val_loss: 0.5779 - val_accuracy: 0.8024\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5568 - accuracy: 0.8067 - val_loss: 0.6452 - val_accuracy: 0.7844\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5471 - accuracy: 0.8093 - val_loss: 0.6095 - val_accuracy: 0.7952\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5424 - accuracy: 0.8112 - val_loss: 0.5556 - val_accuracy: 0.8100\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5378 - accuracy: 0.8124 - val_loss: 0.6079 - val_accuracy: 0.7964\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5289 - accuracy: 0.8153 - val_loss: 0.5667 - val_accuracy: 0.8067\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5232 - accuracy: 0.8192 - val_loss: 0.5417 - val_accuracy: 0.8199\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.5147 - accuracy: 0.8203 - val_loss: 0.5416 - val_accuracy: 0.8211\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5114 - accuracy: 0.8214 - val_loss: 0.5394 - val_accuracy: 0.8194\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5119 - accuracy: 0.8222 - val_loss: 0.5701 - val_accuracy: 0.8131\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5044 - accuracy: 0.8253 - val_loss: 0.5535 - val_accuracy: 0.8152\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5030 - accuracy: 0.8247 - val_loss: 0.5248 - val_accuracy: 0.8267\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.4915 - accuracy: 0.8308 - val_loss: 0.5275 - val_accuracy: 0.8247\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.4908 - accuracy: 0.8294 - val_loss: 0.5169 - val_accuracy: 0.8268\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4929 - accuracy: 0.8296 - val_loss: 0.5372 - val_accuracy: 0.8181\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4880 - accuracy: 0.8316 - val_loss: 0.5492 - val_accuracy: 0.8168\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4789 - accuracy: 0.8345 - val_loss: 0.5043 - val_accuracy: 0.8312\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4799 - accuracy: 0.8335 - val_loss: 0.5483 - val_accuracy: 0.8245\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4781 - accuracy: 0.8369 - val_loss: 0.5676 - val_accuracy: 0.8154\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4734 - accuracy: 0.8362 - val_loss: 0.5664 - val_accuracy: 0.8180\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.4714 - accuracy: 0.8374 - val_loss: 0.5616 - val_accuracy: 0.8150\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4720 - accuracy: 0.8374 - val_loss: 0.5284 - val_accuracy: 0.8243\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4680 - accuracy: 0.8375 - val_loss: 0.5272 - val_accuracy: 0.8278\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4619 - accuracy: 0.8409 - val_loss: 0.5519 - val_accuracy: 0.8234\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4663 - accuracy: 0.8402 - val_loss: 0.5312 - val_accuracy: 0.8236\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4636 - accuracy: 0.8402 - val_loss: 0.5356 - val_accuracy: 0.8249\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4573 - accuracy: 0.8418 - val_loss: 0.5015 - val_accuracy: 0.8351\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4549 - accuracy: 0.8426 - val_loss: 0.5298 - val_accuracy: 0.8320\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x244c1f18cd0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005)\n",
        "\n",
        "\n",
        "model_supple1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_supple1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=50,\n",
        "              validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compact-still",
      "metadata": {
        "id": "compact-still"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5f9e6a",
      "metadata": {},
      "source": [
        "> This activity helped me understand the building and evaluation of convolutional neural networks. Understanding the whole convolutional neural networks is pretty confusing at first, due to its multiple layered architecture, and some of its paramters being new knowledge to me. As time goes by and endless hours of looking into my screen, I somehow understood the architecture of the CNN. Training the model is time consuming, so I used a different kernel, named CUDA, where it utilizes the computer's GPU for faster training. Hyptertuning the parameters is pretty challenging, but it is needed for higher accuracy and low loss. Overall, this activity helped me understand the whole concept of building and evaluating a model using convolutional neural networks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
